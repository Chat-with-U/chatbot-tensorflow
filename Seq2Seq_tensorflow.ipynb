{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_tensorflow.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-msl9nJOjbK"
      },
      "source": [
        "# Chat with U\n",
        "> seq2seq 모델과 Tensorflow로 제작한 Chatbot 튜토리얼입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Busa-L_bWqSk"
      },
      "source": [
        "### Dataset Download\n",
        "Chatbot 학습에 필요한 Dataset을 불러옵니다.\n",
        "- [songys/Chatbot_data](https://github.com/songys/Chatbot_data.git)\n",
        "- 문답 페어 11,876개\n",
        "- `Q`: 질문\n",
        "- `A`: 답변"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_X3S-Uwsvmf"
      },
      "source": [
        "!git clone https://github.com/songys/Chatbot_data.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIIYk_and26i"
      },
      "source": [
        "import pandas as pd\n",
        "corpus = pd.read_csv('/content/Chatbot_data/ChatbotData.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoMDCy1gukBo"
      },
      "source": [
        "corpus.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwYc2_IwwVf_"
      },
      "source": [
        "corpus.Q.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEgGVt2lxjUb"
      },
      "source": [
        "corpus.A.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rk1M9UgvlIB"
      },
      "source": [
        "# dataset을 list 형태로 변환\n",
        "q_list = []\n",
        "a_list = []\n",
        "\n",
        "for q, a in zip(corpus.Q, corpus.A):\n",
        "    q_list.append(q)\n",
        "    a_list.append(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ZnH7i4oZOO"
      },
      "source": [
        "# RAM 용량 제한으로 인한 데이터 개수 줄이기\n",
        "q_list = q_list[:1000]\n",
        "a_list = a_list[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKfK8VknRtKt"
      },
      "source": [
        "q_list[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-RogEinyQBB"
      },
      "source": [
        "### Preprocess\n",
        "형태소 분석\n",
        "- Konlpy의 Okt 분석기를 사용합니다.\n",
        "   \n",
        "\n",
        "토큰 추가\n",
        "- `SOS`: Start Of Sentence\n",
        "- `EOS`: End Of Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R3QyDzLyeAJ"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGxWDw8myjt4"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bw1q6QKvBoT"
      },
      "source": [
        "sentence = \"오늘은 먹고싶은게 딱히 없지만, 딱새우는 먹고싶어요\"\n",
        "okt.morphs(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAz15aS-Ug1L"
      },
      "source": [
        "# 형태소 분석으로 분할된 단어들을 공백 기준으로 분리\n",
        "def process_morph(sentence):\n",
        "    return ' '.join(okt.morphs(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "555vP37oZXYv"
      },
      "source": [
        "# 질문과 답변을 분리해서 처리\n",
        "def morph_and_token(sentence, is_question=True):\n",
        "    sentence = process_morph(sentence)\n",
        "    if is_question:\n",
        "        return sentence\n",
        "    else:\n",
        "        return ('<SOS> ' + sentence, sentence + ' <EOS>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC4a0pnPaXsa"
      },
      "source": [
        "def preprocess(q_list, a_list):\n",
        "    questions = []\n",
        "    answer_input = []\n",
        "    answer_output = []\n",
        "\n",
        "    for q in q_list:\n",
        "        question = morph_and_token(q, is_question=True)\n",
        "        questions.append(question)\n",
        "\n",
        "    for a in a_list:\n",
        "        input_, output_ = morph_and_token(a, is_question=False)\n",
        "        answer_input.append(input_)\n",
        "        answer_output.append(output_)\n",
        "\n",
        "    return questions, answer_input, answer_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM_lSZftWtBg"
      },
      "source": [
        "### Dataset Split\n",
        "Encoder, Decoder의 관점으로 Dataset을 재구성합니다.\n",
        "- `questions`: Encoder input  \n",
        "- `answer_input`: Decoder input  \n",
        "- `answer_output`: Decoder output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj41Vz7pbdt5"
      },
      "source": [
        "questions, answer_input, answer_output = preprocess(q_list, a_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvAx6UUhb-Xm"
      },
      "source": [
        "questions[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysZ6Ex-aY5Vh"
      },
      "source": [
        "answer_input[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbcqJpDuY8Xl"
      },
      "source": [
        "answer_output[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCv8XJ98c5Yy"
      },
      "source": [
        "# vocab 제작에 사용\n",
        "all_sentences = questions + answer_input + answer_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOGchkH6eK5o"
      },
      "source": [
        "### Tokenization\n",
        "- Vocab을 만들어줍니다.\n",
        "- Text를 Sequence로 Encoding합니다.\n",
        "- Padding으로 문장의 길이를 일정하게 맞춰줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKsvwDp7eMZb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1TLTDcaendW"
      },
      "source": [
        "# 토큰의 옵션 정의\n",
        "tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7C4eJKvfFXw"
      },
      "source": [
        "# vocab 만들기\n",
        "tokenizer.fit_on_texts(all_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqvwBuRufbKF"
      },
      "source": [
        "# vocab 확인해보기\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    print(f'{word}\\t\\t\\t{index}')\n",
        "    if index > 20:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOtaphqQgLCh"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfSKh3WegWl7"
      },
      "source": [
        "VOCAB_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io8iTO6thZNl"
      },
      "source": [
        "# Text to Sequence Encoding\n",
        "questions_sequence = tokenizer.texts_to_sequences(questions)\n",
        "answer_input_sequence = tokenizer.texts_to_sequences(answer_input)\n",
        "answer_output_sequence = tokenizer.texts_to_sequences(answer_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfajrriEhwki"
      },
      "source": [
        "questions[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrztnFsHhrEF"
      },
      "source": [
        "questions_sequence[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kogPULGIgYlM"
      },
      "source": [
        "# Padding Hyperparameter\n",
        "# 문장을 잘라낼때 뒷부분부터 잘라주고, Padding을 해줄때 뒷부분부터\n",
        "MAX_LENGTH = 30\n",
        "TRUCATING = 'post'\n",
        "PADDING = 'post'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGQR66Ovgzso"
      },
      "source": [
        "questions_padded = pad_sequences(questions_sequence, maxlen=MAX_LENGTH, truncating=TRUCATING, padding=PADDING)\n",
        "answer_input_padded = pad_sequences(answer_input_sequence, maxlen=MAX_LENGTH, truncating=TRUCATING, padding=PADDING)\n",
        "answer_output_padded = pad_sequences(answer_output_sequence, maxlen=MAX_LENGTH, truncating=TRUCATING, padding=PADDING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdzeX-Bwh7sb"
      },
      "source": [
        "questions_padded[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsDfLeAriQlM"
      },
      "source": [
        "questions_padded.shape, answer_input_padded.shape, answer_output_padded.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5wD2LSLidJI"
      },
      "source": [
        "### Vectorization\n",
        "- 각 단어들을 One-Hot Encoding 변환\n",
        "- Vocab의 index를 참조해 다시 text 형태로 변환 (예측 과정에서 호출)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUZvkiGijJ5"
      },
      "source": [
        "#One-Hot Encoding\n",
        "def convert_to_one_hot(padded):\n",
        "    one_hot_vector = np.zeros((len(padded), MAX_LENGTH, VOCAB_SIZE))\n",
        "\n",
        "    for i, sequence in enumerate(padded):\n",
        "        for j, index in enumerate(sequence):\n",
        "            one_hot_vector[i, j, index] = 1\n",
        "    \n",
        "    return one_hot_vector    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iFoezMlkbGt"
      },
      "source": [
        "answer_input_one_hot = convert_to_one_hot(answer_input_padded)\n",
        "answer_output_one_hot = convert_to_one_hot(answer_output_padded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqGhQm8akeuy"
      },
      "source": [
        "answer_input_one_hot[0].shape, answer_output_one_hot[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ouP5m9hqqd5"
      },
      "source": [
        "# 예측 값을 단어사전에서 찾아와 문자열로 변환\n",
        "def index_to_text(indexs, end_token):\n",
        "    sentence = ' '\n",
        "\n",
        "    for i in indexs:\n",
        "        if i == end_token:\n",
        "            break;\n",
        "\n",
        "        if i > 0 and tokenizer.index_word[i] is not None:\n",
        "            sentence += tokenizer.index_word[i]\n",
        "        else:\n",
        "            sentence += ''\n",
        "\n",
        "        sentence += ' '\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8vWpQxlbYky"
      },
      "source": [
        "### Generate Model\n",
        "- Encoder 정의\n",
        "- Decoder 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV-J7zDnrQSS"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XMpXXGNaEfm"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps)\n",
        "        self.dropout = Dropout(0.2)\n",
        "        self.lstm = LSTM(units, return_state=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout(x)\n",
        "        x.hidden_state, call_state = self.lstm(x)\n",
        "        return [hidden_state, cell_state]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QehXIgUBbnKp"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps)\n",
        "        self.dropout = Dropout(0.2)\n",
        "        self.lstm = LSTM(units, return_state=True, return_sequences=True, )\n",
        "\n",
        "    def call(self, inputs, initial_state):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout(x)\n",
        "        x, hidden_state, cell_state = self.lstm(x, initial_state=initial_state)\n",
        "        x = self.dense(x)\n",
        "        return x, hidden_state, cell_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HZlLmHkh_yT"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leyhNXDzmdKR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}