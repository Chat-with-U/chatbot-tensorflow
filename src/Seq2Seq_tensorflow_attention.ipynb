{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_tensorflow_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-msl9nJOjbK"
      },
      "source": [
        "# Chatbot Tensorflow\n",
        "> Attention Mechanism을 적용한 seq2seq 모델과 Tensorflow, Keras로 제작한 Chatbot 튜토리얼입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Busa-L_bWqSk"
      },
      "source": [
        "### Dataset Download\n",
        "Chatbot 학습에 필요한 Dataset을 불러옵니다.\n",
        "- [songys/Chatbot_data](https://github.com/songys/Chatbot_data.git)\n",
        "- 문답 페어 11,876개\n",
        "- `Q`: 질문\n",
        "- `A`: 답변"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_X3S-Uwsvmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ef8f00-e278-4e43-f46b-c0511b4e27d3"
      },
      "source": [
        "!git clone https://github.com/songys/Chatbot_data.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Chatbot_data'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 50 (delta 17), reused 2 (delta 1), pack-reused 18\u001b[K\n",
            "Unpacking objects: 100% (50/50), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIIYk_and26i"
      },
      "source": [
        "import pandas as pd\n",
        "corpus = pd.read_csv('/content/Chatbot_data/ChatbotData.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoMDCy1gukBo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "cccd58de-62a1-4c54-8eaa-b4917ed66c1f"
      },
      "source": [
        "corpus.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwYc2_IwwVf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2402510-7a9b-4aa8-e233-a63d5e99674c"
      },
      "source": [
        "# Question data\n",
        "corpus.Q.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0             12시 땡!\n",
              "1        1지망 학교 떨어졌어\n",
              "2       3박4일 놀러가고 싶다\n",
              "3    3박4일 정도 놀러가고 싶다\n",
              "4            PPL 심하네\n",
              "Name: Q, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEgGVt2lxjUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da187ab5-aa96-4e92-ee2d-d1f2f991d7d6"
      },
      "source": [
        "# Answer data\n",
        "corpus.A.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     하루가 또 가네요.\n",
              "1      위로해 드립니다.\n",
              "2    여행은 언제나 좋죠.\n",
              "3    여행은 언제나 좋죠.\n",
              "4     눈살이 찌푸려지죠.\n",
              "Name: A, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rk1M9UgvlIB"
      },
      "source": [
        "# dataset의 type을 list 형태로 변환\n",
        "q_list = []\n",
        "a_list = []\n",
        "\n",
        "for q, a in zip(corpus.Q, corpus.A):\n",
        "    q_list.append(q)\n",
        "    a_list.append(a)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ZnH7i4oZOO"
      },
      "source": [
        "# RAM 용량 제한으로 인한 데이터 개수 조정\n",
        "q_list = q_list[:3000]\n",
        "a_list = a_list[:3000]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKfK8VknRtKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daad5940-d77e-428f-cf11-7fd1794cae96"
      },
      "source": [
        "q_list[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-RogEinyQBB"
      },
      "source": [
        "### Preprocess\n",
        "형태소 분석\n",
        "- Konlpy의 Okt 분석기를 사용합니다.\n",
        "   \n",
        "\n",
        "토큰 추가\n",
        "- `SOS`: Start Of Sentence\n",
        "- `EOS`: End Of Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R3QyDzLyeAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd949e7-eb64-48b4-b716-d1e760af26f7"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 222 kB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 71.5 MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGxWDw8myjt4"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bw1q6QKvBoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e198bc3-af57-4669-e12b-6c2e61d3d274"
      },
      "source": [
        "sentence = \"오늘은 즐거운 자연어처리를 해보았어요\"\n",
        "okt.morphs(sentence)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['오늘', '은', '즐거운', '자연어', '처리', '를', '해보았어요']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAz15aS-Ug1L"
      },
      "source": [
        "# 형태소 분석으로 분할된 단어들을 공백 기준으로 분리\n",
        "def process_morph(sentence):\n",
        "    return ' '.join(okt.morphs(sentence))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "555vP37oZXYv"
      },
      "source": [
        "# 질문과 답변을 분리해서 형태소 분석 및 토큰 추가\n",
        "def morph_and_token(sentence, is_question=True):\n",
        "    sentence = process_morph(sentence)\n",
        "    if is_question:\n",
        "        return sentence\n",
        "    else:\n",
        "        return ('<SOS> ' + sentence, sentence + ' <EOS>')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC4a0pnPaXsa"
      },
      "source": [
        "def preprocess(q_list, a_list):\n",
        "    questions = []\n",
        "    answer_input = []\n",
        "    answer_output = []\n",
        "\n",
        "    for q in q_list:\n",
        "        question = morph_and_token(q, is_question=True)\n",
        "        questions.append(question)\n",
        "\n",
        "    for a in a_list:\n",
        "        input_, output_ = morph_and_token(a, is_question=False)\n",
        "        answer_input.append(input_)\n",
        "        answer_output.append(output_)\n",
        "\n",
        "    return questions, answer_input, answer_output"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM_lSZftWtBg"
      },
      "source": [
        "### Dataset Split\n",
        "Encoder, Decoder의 관점으로 Dataset을 재구성합니다.\n",
        "- `questions`: Encoder input  \n",
        "- `answer_input`: Decoder input  \n",
        "- `answer_output`: Decoder output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj41Vz7pbdt5"
      },
      "source": [
        "questions, answer_input, answer_output = preprocess(q_list, a_list)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvAx6UUhb-Xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24154fdc-b287-4775-d43e-b54e834a38ec"
      },
      "source": [
        "questions[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12시 땡 !', '1 지망 학교 떨어졌어', '3 박 4일 놀러 가고 싶다', '3 박 4일 정도 놀러 가고 싶다', 'PPL 심하네']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysZ6Ex-aY5Vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553f6415-f897-4047-e666-e18dfc3ca3ed"
      },
      "source": [
        "answer_input[:5]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<SOS> 하루 가 또 가네요 .',\n",
              " '<SOS> 위로 해 드립니다 .',\n",
              " '<SOS> 여행 은 언제나 좋죠 .',\n",
              " '<SOS> 여행 은 언제나 좋죠 .',\n",
              " '<SOS> 눈살 이 찌푸려지죠 .']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbcqJpDuY8Xl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b5182d-413d-4a7a-f708-22bc048bef49"
      },
      "source": [
        "answer_output[:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['하루 가 또 가네요 . <EOS>',\n",
              " '위로 해 드립니다 . <EOS>',\n",
              " '여행 은 언제나 좋죠 . <EOS>',\n",
              " '여행 은 언제나 좋죠 . <EOS>',\n",
              " '눈살 이 찌푸려지죠 . <EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCv8XJ98c5Yy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7daeb1f-e8cd-43fd-c36b-74fe9df645cc"
      },
      "source": [
        "# vocab 제작에 사용\n",
        "all_sentences = questions + answer_input + answer_output\n",
        "all_sentences[:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12시 땡 !', '1 지망 학교 떨어졌어', '3 박 4일 놀러 가고 싶다', '3 박 4일 정도 놀러 가고 싶다', 'PPL 심하네']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOGchkH6eK5o"
      },
      "source": [
        "### Tokenization\n",
        "- Vocab을 만들어줍니다.\n",
        "- Text를 Sequence로 Encoding합니다.\n",
        "- Padding으로 문장의 길이를 일정하게 맞춰줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKsvwDp7eMZb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1TLTDcaendW"
      },
      "source": [
        "# 토큰의 옵션 정의\n",
        "# OOV는 Out Of Vocabulary\n",
        "tokenizer = Tokenizer(filters='', lower=False, oov_token='<OOV>')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7C4eJKvfFXw"
      },
      "source": [
        "# internal vocabulary 생성\n",
        "tokenizer.fit_on_texts(all_sentences)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOtaphqQgLCh"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfSKh3WegWl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3704016-1c60-4c87-95b6-c936e4a5a6b1"
      },
      "source": [
        "VOCAB_SIZE"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4672"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqvwBuRufbKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8abb4f3-d290-4173-e91e-18e753678c2f"
      },
      "source": [
        "# vocab 확인해보기\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    print(f'{index}\\t\\t\\t{word}')\n",
        "    if index == 10:\n",
        "        break"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\t\t\t<OOV>\n",
            "2\t\t\t.\n",
            "3\t\t\t<SOS>\n",
            "4\t\t\t<EOS>\n",
            "5\t\t\t이\n",
            "6\t\t\t거\n",
            "7\t\t\t을\n",
            "8\t\t\t가\n",
            "9\t\t\t예요\n",
            "10\t\t\t도\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io8iTO6thZNl"
      },
      "source": [
        "# Text to Sequence Encoding\n",
        "questions_sequence = tokenizer.texts_to_sequences(questions)\n",
        "answer_input_sequence = tokenizer.texts_to_sequences(answer_input)\n",
        "answer_output_sequence = tokenizer.texts_to_sequences(answer_output)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oeIioOD9QvG",
        "outputId": "cee207b3-201c-42f8-845a-9671d4f6bc4a"
      },
      "source": [
        "# Vocab에 저장되어있다면 index를 반환\n",
        "tokenizer.word_index['곱창']"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2466"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfajrriEhwki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceec4a50-aac1-468c-db6e-b778b17187ec"
      },
      "source": [
        "questions[:5]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12시 땡 !', '1 지망 학교 떨어졌어', '3 박 4일 놀러 가고 싶다', '3 박 4일 정도 놀러 가고 싶다', 'PPL 심하네']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrztnFsHhrEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ce7f6b-d749-40fa-fff7-0d9e3b81113a"
      },
      "source": [
        "questions_sequence[:5]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2418, 3256, 27],\n",
              " [1353, 3257, 3258, 1354],\n",
              " [1355, 2419, 2420, 282, 156, 78],\n",
              " [1355, 2419, 2420, 2421, 282, 156, 78],\n",
              " [3259, 3260]]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kogPULGIgYlM"
      },
      "source": [
        "# Padding Hyperparameter\n",
        "MAX_LENGTH = 30"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGQR66Ovgzso"
      },
      "source": [
        "# post -> 문장을 잘라낼때 뒷부분부터 잘라주고, Padding을 해줄때 뒷부분부터 채워넣음\n",
        "questions_padded = pad_sequences(questions_sequence, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "answer_input_padded = pad_sequences(answer_input_sequence, maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
        "answer_output_padded = pad_sequences(answer_output_sequence, maxlen=MAX_LENGTH, padding='post', truncating='post')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdzeX-Bwh7sb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5726d0-8c62-4819-d43d-eede029b5cde"
      },
      "source": [
        "questions_padded[:5]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2418, 3256,   27,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [1353, 3257, 3258, 1354,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [1355, 2419, 2420,  282,  156,   78,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [1355, 2419, 2420, 2421,  282,  156,   78,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [3259, 3260,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsDfLeAriQlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a39a44-035e-4f10-afe9-df82325eccb2"
      },
      "source": [
        "questions_padded.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5wD2LSLidJI"
      },
      "source": [
        "### Vectorization\n",
        "- 각 단어들을 One-Hot Encoding 변환\n",
        "- Vocab의 index를 참조해 다시 text 형태로 변환 (예측 과정에서 호출)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrUZvkiGijJ5"
      },
      "source": [
        "#One-Hot Encoding\n",
        "def convert_to_one_hot(padded):\n",
        "    one_hot_vector = np.zeros((len(padded), MAX_LENGTH, VOCAB_SIZE))\n",
        "\n",
        "    for i, sequence in enumerate(padded):\n",
        "        for j, index in enumerate(sequence):\n",
        "            one_hot_vector[i, j, index] = 1\n",
        "    \n",
        "    return one_hot_vector"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iFoezMlkbGt"
      },
      "source": [
        "#answer_input_one_hot = convert_to_one_hot(answer_input_padded)\n",
        "answer_output_one_hot = convert_to_one_hot(answer_output_padded)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqGhQm8akeuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2f78b0-dbe3-4c70-aa70-9594f960e8cc"
      },
      "source": [
        "answer_output_one_hot.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 30, 4672)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlqW-8haVcy6",
        "outputId": "fe5e8e76-ed59-4181-df12-72e9d225cbee"
      },
      "source": [
        "len(answer_output_one_hot[0][0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4672"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ouP5m9hqqd5"
      },
      "source": [
        "# 예측 값을 단어사전에서 찾아와 문자열로 변환\n",
        "def index_to_text(indexs, end_token):\n",
        "    sentence = ' '\n",
        "\n",
        "    for i in indexs:\n",
        "        if i == end_token:\n",
        "            break;\n",
        "\n",
        "        if i > 0 and tokenizer.index_word[i] is not None:\n",
        "            sentence += tokenizer.index_word[i]\n",
        "        else:\n",
        "            sentence += ''\n",
        "\n",
        "        sentence += ' '\n",
        "    return sentence"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8vWpQxlbYky"
      },
      "source": [
        "### Generate Model\n",
        "- Encoder 정의\n",
        "- Decoder 정의\n",
        "- Seq2Seq에 Attention Mechanism 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV-J7zDnrQSS"
      },
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Attention\n",
        "from keras.models import Model"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XMpXXGNaEfm"
      },
      "source": [
        "# tf.keras.Model을 상속받아 Encoder 함수를 정의합니다.\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        # tf.keras.Model의 init함수를 호출합니다.\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps)\n",
        "        self.dropout = Dropout(0.2)\n",
        "        self.lstm = LSTM(units, return_sequences=True, return_state=True)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.dropout(x)\n",
        "        H, hidden_state, cell_state = self.lstm(x)\n",
        "        # return all Hidden states and context vector\n",
        "        return H, hidden_state, cell_state"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QehXIgUBbnKp"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = Embedding(vocab_size, embedding_dim, input_length=time_steps)\n",
        "        self.dropout = Dropout(0.2)\n",
        "        self.lstm = LSTM(units, return_state=True, return_sequences=True, )\n",
        "        self.attention = Attention()\n",
        "        self.dense = Dense(vocab_size, activation='softmax')\n",
        "\n",
        "    def __call__(self, inputs, initial_state):\n",
        "        # H는 Encoder 내부에 있는 모든 LSTM의 hidden state\n",
        "        x, h0, c0, H = inputs\n",
        "        x = self.embedding(x)\n",
        "        x = self.dropout(x)\n",
        "        # S는 Decoder 내부에 있는 모든 LSTM의 hidden state\n",
        "        S, hidden_state, cell_state = self.lstm(x, initial_state=[h0, c0])\n",
        "        S_ = tf.concat([h0[:, tf.newaxis, :], S[:, :-1, :]], axis=1)\n",
        "\n",
        "        A = self.attention([S_, H])\n",
        "        y = tf.concat([S, A], axis=-1)\n",
        "        y = self.dense(y)\n",
        "        return y, hidden_state, cell_state"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B36he5dstH_"
      },
      "source": [
        "class Seq2Seq(tf.keras.Model):\n",
        "    def __init__(self, units, vocab_size, embedding_dim, time_steps, start_token, end_token):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.start_token = start_token\n",
        "        self.end_token = end_token\n",
        "        self.time_steps = time_steps\n",
        "\n",
        "        self.encoder = Encoder(units, vocab_size, embedding_dim, time_steps)\n",
        "        self.decoder = Decoder(units, vocab_size, embedding_dim, time_steps)\n",
        "\n",
        "    def __call__(self, inputs, training=True):\n",
        "        # 학습 상태의 경우\n",
        "        if training:\n",
        "            encoder_inputs, decoder_inputs = inputs\n",
        "            #decoder_outputs = decoder_inputs\n",
        "            H, decoder_hidden, decoder_cell = self.encoder(encoder_inputs)\n",
        "            decoder_outputs, _, _ = self.decoder(inputs=[decoder_inputs, decoder_hidden, decoder_cell, H], initial_state=[decoder_inputs, decoder_hidden, decoder_cell, H])\n",
        "            return decoder_outputs\n",
        "\n",
        "        # 예측 상태의 경우\n",
        "        else:\n",
        "            H, decoder_hidden, decoder_cell = self.encoder(inputs)\n",
        "            target_seq = tf.constant([[self.start_token]], dtype=tf.float32)\n",
        "            results = tf.TensorArray(tf.int32, self.time_steps)\n",
        "\n",
        "            # 맨 처음 한번만 <SOS> 토큰을 넣어줍니다.\n",
        "            decoder_outputs = target_seq\n",
        "            for i in tf.range(self.time_steps):\n",
        "                decoder_outputs, decoder_hidden, decoder_cell = self.decoder(inputs=[decoder_outputs, decoder_hidden, decoder_cell, H], initial_state=[decoder_outputs, decoder_hidden, decoder_cell, H])\n",
        "                decoder_outputs = tf.cast(tf.argmax(decoder_outputs, axis=-1), dtype=tf.int32)\n",
        "                decoder_outputs = tf.reshape(decoder_outputs, shape=(1, 1))\n",
        "                results = results.write(i, decoder_outputs)\n",
        "\n",
        "                if decoder_outputs == self.end_token:\n",
        "                    break;\n",
        "\n",
        "                #target_seq = decoder_outputs\n",
        "                #context_vector = [decoder_hidden, decoder_cell]\n",
        "\n",
        "            return tf.reshape(results.stack(), shape=(1, self.time_steps))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HZlLmHkh_yT"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB1UF1XHT00H"
      },
      "source": [
        "# Training Hyperparameter\n",
        "BATCH_SIZE = 16\n",
        "EMBEDDING_DIM = 128\n",
        "TIME_STEPS = MAX_LENGTH\n",
        "\n",
        "START_TOKEN = tokenizer.word_index['<SOS>']\n",
        "END_TOKEN = tokenizer.word_index['<EOS>']\n",
        "\n",
        "# LSTM에 들어가는 UNITS\n",
        "UNITS = 128\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "DATA_LENGTH = len(questions)\n",
        "SAMPLE_SIZE = 3\n",
        "CALL_NUM = 20"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69qlY_p4WeCV"
      },
      "source": [
        "# 모델 생성 및 컴파일\n",
        "seq2seq = Seq2Seq(UNITS, VOCAB_SIZE, EMBEDDING_DIM, TIME_STEPS, START_TOKEN, END_TOKEN)\n",
        "seq2seq.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B30jBhDXbPr"
      },
      "source": [
        "# 예측 함수\n",
        "def make_prediction(model, question_inputs):\n",
        "    results = model(inputs=question_inputs, training=False)\n",
        "    results = np.asarray(results).reshape(-1)\n",
        "    return results"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjd5TOg1X6l4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c39b95-e14b-4b99-f389-a5009d683b85"
      },
      "source": [
        "# 주어진 epoch만큼 모델 학습\n",
        "for cnt in range(CALL_NUM):\n",
        "    print(f'processing epoch: {cnt * 10 + 1}...')\n",
        "    seq2seq.fit([questions_padded, answer_input_padded],\n",
        "                answer_output_one_hot,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                epochs=10,\n",
        "                )\n",
        "    \n",
        "    samples = np.random.randint(DATA_LENGTH, size=SAMPLE_SIZE)\n",
        "\n",
        "    for idx in samples:\n",
        "        question_inputs = questions_padded[idx]\n",
        "        results = make_prediction(seq2seq, np.expand_dims(question_inputs, 0))\n",
        "        results = index_to_text(results, END_TOKEN)\n",
        "\n",
        "        print(f'Q: {questions[idx]}')\n",
        "        print(f'A: {results}\\n')\n",
        "        print()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing epoch: 1...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 8s 14ms/step - loss: 1.9170 - acc: 0.7862\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.1343 - acc: 0.8374\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.0550 - acc: 0.8411\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.0070 - acc: 0.8456\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.9662 - acc: 0.8491\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.9287 - acc: 0.8524\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.8881 - acc: 0.8558\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.8460 - acc: 0.8602\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.8044 - acc: 0.8639\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.7630 - acc: 0.8690\n",
            "Q: 너 도 고민 있어 ?\n",
            "A:  잘 사람 이 죠 . \n",
            "\n",
            "\n",
            "Q: 성형 무서워\n",
            "A:  잘 사람 이 죠 . \n",
            "\n",
            "\n",
            "Q: 뭐 입고 가지 ?\n",
            "A:  잘 사람 이 죠 . \n",
            "\n",
            "\n",
            "processing epoch: 11...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.7255 - acc: 0.8734\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.6892 - acc: 0.8783\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.6532 - acc: 0.8839\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.6165 - acc: 0.8892\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.5815 - acc: 0.8950\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.5477 - acc: 0.9007\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.5142 - acc: 0.9071\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.4832 - acc: 0.9134\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.4551 - acc: 0.9182\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.4367 - acc: 0.9223\n",
            "Q: 도시락 싸가지 고 다닐까\n",
            "A:  좋은 곳 으로 데려다 줄 거 예요 . \n",
            "\n",
            "\n",
            "Q: 수영 하러 다닐까 ?\n",
            "A:  좋은 결과 있을 거 예요 . \n",
            "\n",
            "\n",
            "Q: 뜻밖 의 고민 을 하고 있어\n",
            "A:  저 도 궁금하네요 . \n",
            "\n",
            "\n",
            "processing epoch: 21...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.4064 - acc: 0.9281\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.3824 - acc: 0.9331\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.3618 - acc: 0.9369\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.3435 - acc: 0.9410\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.3263 - acc: 0.9436\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.3106 - acc: 0.9465\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2969 - acc: 0.9481\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2839 - acc: 0.9505\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2746 - acc: 0.9521\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2627 - acc: 0.9539\n",
            "Q: 공부 때려 치워야 하나\n",
            "A:  잘 해결 되길 바라요 . \n",
            "\n",
            "\n",
            "Q: 나 한테 만은 완전 솔직했으면\n",
            "A:  잘 하는 게 말 하는 사람 이 좋을 거 예요 . \n",
            "\n",
            "\n",
            "Q: 삶 에 지쳤어\n",
            "A:  저 도 밥 먹고 싶어요 \n",
            "\n",
            "\n",
            "processing epoch: 31...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2524 - acc: 0.9554\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2458 - acc: 0.9558\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2365 - acc: 0.9572\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2291 - acc: 0.9581\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2240 - acc: 0.9588\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2147 - acc: 0.9598\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2076 - acc: 0.9608\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.2017 - acc: 0.9614\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1957 - acc: 0.9621\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1925 - acc: 0.9628\n",
            "Q: 발레 배워 보려고\n",
            "A:  너무 불안해하지 않아도 돼요 . \n",
            "\n",
            "\n",
            "Q: 결혼 해도 되나\n",
            "A:  공부 하면 더 많은 선택 을 할 수 있죠 . \n",
            "\n",
            "\n",
            "Q: 고집 센 사람\n",
            "A:  저 는 위로 해드리는 로봇 이에요 . \n",
            "\n",
            "\n",
            "processing epoch: 41...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1857 - acc: 0.9634\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1818 - acc: 0.9640\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1769 - acc: 0.9645\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1796 - acc: 0.9638\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1701 - acc: 0.9649\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1635 - acc: 0.9657\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1582 - acc: 0.9663\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1543 - acc: 0.9666\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1510 - acc: 0.9671\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1475 - acc: 0.9674\n",
            "Q: 물리치료 받아야겠다\n",
            "A:  저 도 즐거워요 \n",
            "\n",
            "\n",
            "Q: 나 은근 무시 하는 애 있어\n",
            "A:  자책 하지 마세요 . \n",
            "\n",
            "\n",
            "Q: 보기 만해 도 짜증 이 나지\n",
            "A:  가장 확실한 시간 은 오늘이 에요 . 어제 와 내일 을 놓고 고민 하느라 시간 을 낭비하지 마세요 . \n",
            "\n",
            "\n",
            "processing epoch: 51...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1497 - acc: 0.9668\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1484 - acc: 0.9669\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1394 - acc: 0.9683\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1360 - acc: 0.9688\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1329 - acc: 0.9690\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1293 - acc: 0.9695\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1256 - acc: 0.9700\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1204 - acc: 0.9707\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1181 - acc: 0.9711\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1164 - acc: 0.9712\n",
            "Q: 상관 없는 이야기 만 해\n",
            "A:  잊어버리세요 . \n",
            "\n",
            "\n",
            "Q: 길이 안보 여\n",
            "A:  얼른 청소 하세요 . \n",
            "\n",
            "\n",
            "Q: 매운 닭발 먹고 싶다 .\n",
            "A:  멍 때리고 있죠 . \n",
            "\n",
            "\n",
            "processing epoch: 61...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1121 - acc: 0.9720\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1108 - acc: 0.9723\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1100 - acc: 0.9727\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1075 - acc: 0.9730\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1035 - acc: 0.9739\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.1020 - acc: 0.9739\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0967 - acc: 0.9750\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0977 - acc: 0.9748\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0929 - acc: 0.9760\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0883 - acc: 0.9769\n",
            "Q: 세탁소 가기 도 귀찮네\n",
            "A:  달력 에 적어 보세요 . \n",
            "\n",
            "\n",
            "Q: 수분크림 바르고 자면 나아질거야\n",
            "A:  예뻐질 거 예요 . \n",
            "\n",
            "\n",
            "Q: 내일 약속 있는데 날씨 좋았으면\n",
            "A:  날씨 가 안 좋더라도 데이트 는 성공 적 일 거 예요 . \n",
            "\n",
            "\n",
            "processing epoch: 71...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0861 - acc: 0.9775\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0808 - acc: 0.9788\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0780 - acc: 0.9794\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0766 - acc: 0.9796\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0756 - acc: 0.9798\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0731 - acc: 0.9806\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0695 - acc: 0.9818\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0669 - acc: 0.9824\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0639 - acc: 0.9830\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0623 - acc: 0.9836\n",
            "Q: 독학 하려니까 힘들어\n",
            "A:  더 깊은 공부 할 수 있을 거 예요 . \n",
            "\n",
            "\n",
            "Q: 마딩 있는 주택 에 살 고 싶어\n",
            "A:  돈 을 모아 땅 을 사세요 . \n",
            "\n",
            "\n",
            "Q: 봄날 이 기대 돼\n",
            "A:  봄 은 항상 두근거려요 . \n",
            "\n",
            "\n",
            "processing epoch: 81...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0620 - acc: 0.9834\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0572 - acc: 0.9851\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0563 - acc: 0.9850\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0535 - acc: 0.9861\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0502 - acc: 0.9867\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0482 - acc: 0.9874\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0461 - acc: 0.9879\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0499 - acc: 0.9869\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0510 - acc: 0.9866\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0417 - acc: 0.9893\n",
            "Q: 너무 불공평한거 같 애\n",
            "A:  환해 보이는 옷 이 요 ! \n",
            "\n",
            "\n",
            "Q: 소문 날까봐 무서워\n",
            "A:  긍정 적 이고 부정 적 인 파급 력 이 모두 세죠 . \n",
            "\n",
            "\n",
            "Q: 몰랐구나\n",
            "A:  저 도 몰랐어요 . \n",
            "\n",
            "\n",
            "processing epoch: 91...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0365 - acc: 0.9911\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0335 - acc: 0.9922\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0327 - acc: 0.9924\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0302 - acc: 0.9929\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0291 - acc: 0.9931\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0291 - acc: 0.9929\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0289 - acc: 0.9930\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0290 - acc: 0.9928\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0279 - acc: 0.9931\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0291 - acc: 0.9927\n",
            "Q: 앞 으로 나가지 않고 이렇게만 살고싶어\n",
            "A:  꼭 앞 으로 나가야 하는 건 아니에요 . \n",
            "\n",
            "\n",
            "Q: 변기 막혔어\n",
            "A:  얼른 뚫어 보아 요 . \n",
            "\n",
            "\n",
            "Q: 난 정말 안되겠다\n",
            "A:  다 잘 될 거 예요 . \n",
            "\n",
            "\n",
            "processing epoch: 101...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0272 - acc: 0.9934\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0242 - acc: 0.9943\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0219 - acc: 0.9949\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0229 - acc: 0.9947\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0206 - acc: 0.9953\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0196 - acc: 0.9953\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0178 - acc: 0.9959\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0173 - acc: 0.9961\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0176 - acc: 0.9960\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0162 - acc: 0.9965\n",
            "Q: 내 인생 답 없어\n",
            "A:  정답 을 찾아 야할 필요 는 없어요 . \n",
            "\n",
            "\n",
            "Q: 아무 것 도 하기가 싫어\n",
            "A:  아무 것 도 안해 도 괜찮아요 . \n",
            "\n",
            "\n",
            "Q: 싸웠는데 화해 어떻게 하지\n",
            "A:  대화 를 많이 해서 바로 바로 풀어요 . \n",
            "\n",
            "\n",
            "processing epoch: 111...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0164 - acc: 0.9959\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0172 - acc: 0.9961\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0185 - acc: 0.9957\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0216 - acc: 0.9949\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0177 - acc: 0.9957\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0133 - acc: 0.9970\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0111 - acc: 0.9977\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0092 - acc: 0.9982\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0093 - acc: 0.9981\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0141 - acc: 0.9968\n",
            "Q: 귀농 어때 ?\n",
            "A:  생각 하기는 쉬운데 실천 하기는 어려운 것 같아요 . \n",
            "\n",
            "\n",
            "Q: 벌써 방학 끝 이라니\n",
            "A:  방학 이 참 짧죠 . \n",
            "\n",
            "\n",
            "Q: 머리 안 감았더니 떡 졌어\n",
            "A:  앞머리 만이라도 감으세요 . \n",
            "\n",
            "\n",
            "processing epoch: 121...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0126 - acc: 0.9969\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0105 - acc: 0.9978\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0086 - acc: 0.9983\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0073 - acc: 0.9986\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0062 - acc: 0.9988\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0055 - acc: 0.9991\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0050 - acc: 0.9991\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0047 - acc: 0.9992\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0059 - acc: 0.9987\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0078 - acc: 0.9982\n",
            "Q: 시험 끝나고 만나고 싶어\n",
            "A:  만날 날 까지 기다릴게요 \n",
            "\n",
            "\n",
            "Q: 대놓고 말 했으면 좋겠어\n",
            "A:  말 하는 습관 차이 인 듯 합니다 . \n",
            "\n",
            "\n",
            "Q: 꽃다발 선물 괜찮지 ?\n",
            "A:  센스 있는 선물 이에요 . \n",
            "\n",
            "\n",
            "processing epoch: 131...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0110 - acc: 0.9972\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0140 - acc: 0.9962\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0152 - acc: 0.9958\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0137 - acc: 0.9967\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0103 - acc: 0.9973\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0086 - acc: 0.9981\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0071 - acc: 0.9985\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0055 - acc: 0.9989\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0035 - acc: 0.9994\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0031 - acc: 0.9994\n",
            "Q: 건물 주 되고싶어\n",
            "A:  이룰 수 있을 거 예요 . \n",
            "\n",
            "\n",
            "Q: 쓸데 없는 걱정 1 위 연예인 걱정\n",
            "A:  동감 입니다 . \n",
            "\n",
            "\n",
            "Q: 미세먼지 가 너무 많아\n",
            "A:  살기 더 힘들어졌어요 . \n",
            "\n",
            "\n",
            "processing epoch: 141...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0025 - acc: 0.9996\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0024 - acc: 0.9996\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0028 - acc: 0.9994\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0038 - acc: 0.9992\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0061 - acc: 0.9986\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0120 - acc: 0.9969\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0140 - acc: 0.9964\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0110 - acc: 0.9973\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0074 - acc: 0.9983\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0050 - acc: 0.9990\n",
            "Q: 면도 하는 게 낫겠지 ?\n",
            "A:  깔끔한게 좋죠 . \n",
            "\n",
            "\n",
            "Q: 소개 해 준다는 사람 도 없어\n",
            "A:  친구 한테 부탁 해보세요 . \n",
            "\n",
            "\n",
            "Q: 소개 해 준다는 사람 도 없어\n",
            "A:  친구 한테 부탁 해보세요 . \n",
            "\n",
            "\n",
            "processing epoch: 151...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0039 - acc: 0.9991\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0028 - acc: 0.9994\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0024 - acc: 0.9995\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0025 - acc: 0.9994\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - acc: 0.9995\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0021 - acc: 0.9994\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0065 - acc: 0.9984\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0081 - acc: 0.9978\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0116 - acc: 0.9969\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0119 - acc: 0.9969\n",
            "Q: 뭐 하는 분이세요 ?\n",
            "A:  저 는 마음 을 이어주는 위로 봇 입니다 . \n",
            "\n",
            "\n",
            "Q: 남자친구 가 사업 시 작 한 대\n",
            "A:  바쁠 때 힘 이 되어 주세요 . \n",
            "\n",
            "\n",
            "Q: 남친 보여줄까\n",
            "A:  네 알려 주세요 ! \n",
            "\n",
            "\n",
            "processing epoch: 161...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0068 - acc: 0.9985\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0038 - acc: 0.9992\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0023 - acc: 0.9995\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - acc: 0.9995\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - acc: 0.9996\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - acc: 0.9996\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9996\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9997\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9996\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9996\n",
            "Q: 그냥 혼자 밥 이나 먹어야지\n",
            "A:  밥심 으로 사는 거 죠 . \n",
            "\n",
            "\n",
            "Q: 스트레스 가 안 풀려\n",
            "A:  운동 을 해보세요 . \n",
            "\n",
            "\n",
            "Q: 날씨 건조한 거 같 애\n",
            "A:  미스트 나 가습기 , 젖은 수건 등 을 사용 해보세요 . \n",
            "\n",
            "\n",
            "processing epoch: 171...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9996\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9996\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9996\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0156 - acc: 0.9959\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0184 - acc: 0.9949\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0094 - acc: 0.9975\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0052 - acc: 0.9987\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0028 - acc: 0.9993\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0023 - acc: 0.9995\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - acc: 0.9996\n",
            "Q: 스타트업 에 가도 될까 ?\n",
            "A:  모 아니면 도예 요 . \n",
            "\n",
            "\n",
            "Q: 봉사활동 해볼까\n",
            "A:  의미 있는 일이 네 요 . \n",
            "\n",
            "\n",
            "Q: 모임 에서 만났어\n",
            "A:  꿩 먹고 알 먹고네요 . \n",
            "\n",
            "\n",
            "processing epoch: 181...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - acc: 0.9996\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9996\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9996\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - acc: 0.9997\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - acc: 0.9996\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - acc: 0.9996\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - acc: 0.9997\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 9.7694e-04 - acc: 0.9996\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - acc: 0.9996\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 9.8206e-04 - acc: 0.9997\n",
            "Q: 수학여행 때 뭐 입지 ?\n",
            "A:  뭘 입어도 예뻐요 . \n",
            "\n",
            "\n",
            "Q: 남자친구 가 데려다 줬어\n",
            "A:  고마운 마음 을 전해 주세요 . \n",
            "\n",
            "\n",
            "Q: 내 실력 좀 쩌 는 듯\n",
            "A:  동감 이에요 . \n",
            "\n",
            "\n",
            "processing epoch: 191...\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - acc: 0.9996\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0017 - acc: 0.9995\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0103 - acc: 0.9973\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0185 - acc: 0.9949\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0137 - acc: 0.9961\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0069 - acc: 0.9982\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0036 - acc: 0.9991\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0020 - acc: 0.9995\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - acc: 0.9996\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - acc: 0.9996\n",
            "Q: 결혼 준비 하는데 돈 얼마나 드 나\n",
            "A:  욕심 에 따라 천지 차이 일 거 예요 . \n",
            "\n",
            "\n",
            "Q: 나 백수 야\n",
            "A:  저 랑 놀아요 . \n",
            "\n",
            "\n",
            "Q: 공황장애 생겼어 .\n",
            "A:  꾸준히 약 먹고 치료 해보세요 . \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEJtiPeYXe8D"
      },
      "source": [
        "### Prediction\n",
        "- 사용자로부터 입력받은 문장의 전처리를 해줍니다.\n",
        "- 전처리 한 문장을 입력해 예측값을 얻습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4BgXwu9puS1"
      },
      "source": [
        "# 입력받은 문장을 전처리\n",
        "def make_question(sentence):\n",
        "    sentence = morph_and_token(sentence)\n",
        "    question_sequence = tokenizer.texts_to_sequences([sentence])\n",
        "    question_padded = pad_sequences(question_sequence, maxlen=MAX_LENGTH, truncating='post', padding='post')\n",
        "    return question_padded"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uVqOGWIqvJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22870f55-a1d7-4ce3-82f8-d08ed4b04695"
      },
      "source": [
        "make_question('1지망 학교 떨어졌어')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1353, 3257, 3258, 1354,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAK9H8hoq3dq"
      },
      "source": [
        "# make_question으로 전처리 후 make_prediction으로 예측\n",
        "def run_chatbot(question):\n",
        "    question_inputs = make_question(question)\n",
        "    results = make_prediction(seq2seq, question_inputs)\n",
        "    results = index_to_text(results, END_TOKEN)\n",
        "    return results"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS6l8LixrwPF"
      },
      "source": [
        "### Test\n",
        "- 챗봇과 대화를 이어갈 수 있는 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPTArwDjryVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29df5a5d-684e-4fe5-f207-047b241a39de"
      },
      "source": [
        "EXIT = \"대화종료\"\n",
        "input_values = []\n",
        "\n",
        "while True:\n",
        "    user_input = input('\\nQuestion: ')\n",
        "    if user_input == EXIT:\n",
        "        break\n",
        "    input_values.append(user_input)\n",
        "    answer = run_chatbot(user_input)\n",
        "    print(f'Answer: {answer}')\n",
        "    print('---------------------------')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question: 비 오는 날 별로 안 좋아해\n",
            "Answer:  너무 아름답죠 . \n",
            "---------------------------\n",
            "\n",
            "Question: 배고파\n",
            "Answer:  얼른 맛 난 음식 드세요 . \n",
            "---------------------------\n",
            "\n",
            "Question: 나 너무 지쳤어\n",
            "Answer:  지칠 때 는 쉬어도 돼요 . \n",
            "---------------------------\n",
            "\n",
            "Question: 하고싶은게 너무 많아\n",
            "Answer:  잘 하고 있을 거 예요 . \n",
            "---------------------------\n",
            "\n",
            "Question: 고마워\n",
            "Answer:  저 도 보고 싶어요 . \n",
            "---------------------------\n",
            "\n",
            "Question: 보고싶지는 않아\n",
            "Answer:  저 는 주 당 이에요 . \n",
            "---------------------------\n",
            "\n",
            "Question: 오늘은 기분이 너무 좋아\n",
            "Answer:  감기 조심하세요 . \n",
            "---------------------------\n",
            "\n",
            "Question: 날씨가 좋다\n",
            "Answer:  그게 최고 죠 . \n",
            "---------------------------\n",
            "\n",
            "Question: 보고싶은 영화가 많아\n",
            "Answer:  나중 에 없애주세요 . \n",
            "---------------------------\n",
            "\n",
            "Question: 대화종료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfbFbYGVkZ8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2ad44a-42d0-4095-c43a-aaef94b7a76b"
      },
      "source": [
        "input_values"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['비 오는 날 별로 안 좋아해',\n",
              " '배고파',\n",
              " '나 너무 지쳤어',\n",
              " '하고싶은게 너무 많아',\n",
              " '고마워',\n",
              " '보고싶지는 않아',\n",
              " '오늘은 기분이 너무 좋아',\n",
              " '날씨가 좋다',\n",
              " '보고싶은 영화가 많아']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1inGecgSNvVF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}